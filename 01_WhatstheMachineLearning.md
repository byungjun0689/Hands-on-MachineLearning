### PART 1

# 1. 한눈에 보는 머신러닝.

### 1.1 머신러닝이란? 

머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학.

- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게하는 연구 분야. - 아서사무엘
- 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. - 톰 미첼



### 1.2 왜 머신러닝을 사용하는가?

예를 들어 스팸 메일 필터링을 구현하고자 할 때.

전통적인 방법은 규칙이 복잡해 질 수록 프로그래밍도 길어지고, 만드는 그 규칙마저 복잡해진다. 즉, 유지보수가 힘들어지는 반면, 머신러닝 기반의 필터는 패턴을 감지하여 그 판단 기준을 자동적으로 학습한다. 프로그램이 짧아지고 유지 보수가 용이해진다.



머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있는데 이를 **데이터 마이닝** 이라고 한다.



### 1.3 머신러닝 시스템의 종류 

- 지도, 비지도, 준지도, 강화학습 (사람의 감독 하에 훈련 여부)
- 온라인, 배치 학습 (실시간으로 점진적으로 학습하는지 여부)
- 사례 기반 학습과 모델 기반 학슴 (단순하게 알고있는 데이터 포인트와 새 데이터 포인트를 비굑하는 것인지 아니면 패턴을 발견하여 예측 모델을 만드는 것인지)



#### 1.3.1 지도, 비지도 학습

##### 지도 학습 (Supervised Learning)

- Supervised Learning (지도 학습) : 알고리즘에 주입하는 훈련 데이터에 레이블(Label) 이라는 **답**이 포함.
- Classification :  전형적인 지도 학습. ~인지 아닌지
- Regression : 예측 변수 (predictor variable)이라 부르는 특성(feature)을 이용하여 Target 수치를 예측. 
- 예 ) 
  - k-Nearest Neighbors
  - Linear Regression
  - Logistic Regression
  - Support Vector Machine(SVM)
  - Decision Tree, Random Forests
  - Neural Networks



##### 비지도 학습(Unsupervised Learning)

- 훈련데이터에 레이블이 없는 학습, 시스템의 도움이 없이 학습.
- 알고리즘이 스스로 데이터 사이의 연결고리를 찾는다. 
- Clustering
  - k-Means
  - Hierachical Cluster Analysis (HCA, 계층 군집 분석) => 각 그룹을 더 작은 그룹으로 세분화 가능.
  - Expertation Maximization (기댓값 최대화)
- Visualization & Dimensionality Reduction (차원축소) 
  => 데이터가 어떻게 조직되어있는지 이해할 수 있고 예상하지 못한 패턴을 발견 할 수 있다. 
  => 너무 많은 정보를 잃지 않으면서 데이터를 간소화하는 작업(차원축소), 실행속도도 빨라지고 디스크와 메모리 사용에도 용이 하다. 
  - Principal Componet Analysis(PCA)
  - Kernel PCA
  - Locally-LinearEmbedding(LLE, 지역적 선형 임베딩)
  - t-distributed Stochastic Neighbor Embedding (t-SNE)
- Association Rule Learning => 데이터 사이의 흥미로운 관계를 찾는 학습.
  - Apriori
  - Eclat(이클렛)



##### 준지도학습(Semi Supervised Learning) 

- 레이블이 없는 데이터가 많고 레이블이 있는 데이터가 극히 소수인 데이터.
- 예 ) 구글의 포토 호스팅 서비스, 가족 사진을 모두 올리면 사람 A는 사진 1,5,11에 있고 사람B는 2,5,7에 있다고 자동으로 인식. 이제 시스템에 필요한 것은 사람들이 누구인가 하는 정보, 사람마다 레이블이 하나씩만 주어지면 사진에 있는 모든 사람의 이름을 알 수 있음. 



##### 강화학습(Reinforcement Learning)

학습하는 시스템을 **에이전트**라고 하고 환경을 관찰하여 행동을 실행하고 그 결과를 **보상(reward)** 받고 부정적인 보상에 해당하는 *벌점(penalty)*를 부여. 시간이 지나며 큰 보상을 얻기 위한 **정책(policy)**을 수립하여 스스로 학습.



#### 1.3.2 배치 학습과 온라인 학습.

머신러닝 시스템 분류 기준은 입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부



##### 배치학습 (Batch Learning)

- 우리가 일반적으로 알고 있는 시스템
- 점진적으로 학습 할 수 없다. 시스템을 훈련시키고 적용하면 더이상의 학습이 없이 실행.
- **Offline Learning** 이라고 한다.
- 새로운 데이터에 대해 학습하려면 이전데이터 + 새로운 데이터를 합쳐 다시 학습해야 함.
- 이러한 과정을 쉽게 자동화 될 수 있어서 배치 학습 시스템도 변화에 적응할 수 있음.
- 많은 컴퓨팅 자원이 필요 ( 전체 데이터 학습 )



##### 온라인학습(Online Learning)

- 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련. 
- 매 학습 단계가 빠르고 비용이 적게 듬.
- 중요한 파라미터 중 하나는 얼마나 빠르게 적응할 것인가를 말하는 **Learning Rate(학습률)**





#### 1.3.3 사례 기반 과 모델 기반 학습. 

##### 사례기반학습. 

- 가장 단순히 기억하는 것. 
- 사용자가 스템이라고 지정한 메일과 동일한 메일은 스팸으로 분류. 
- 최악도 아니지만 최선도 아님. 
- 유사한 메일을 구분하도록 필터를 구축할 수 있는데 두 메일 사이의 **Similarity(유사도)**를 축정해야 함. 


##### 모델 기반 학습

- 샘플들의 모델을 만들어 예측에 사용하는 것.
- 예를 들어 선형함수를 통해 삶의 만족도를 GDP로 식을 만들어서 적용 시키는 것. (책 참조)
- 모델이 얼마나 좋은지 측정하는 효용함수 또는 적합도 함수를 정의하거나 얼마나 나쁜지 측정하는 **Cost Function**을 정의.
- **Cost Function**을 최소화 하는 것이 목표.
- 작업 방법 요약
  - 데이터 분석
  - 모델 선택
  - 훈련 데이터로 모델 훈련(Cost function 최소화하는 파라미터를 찾는다.)
  - 새로운 데이터에 모델을 적용해 예측.



### 1.4 머신러닝의 주요 도전 과제

#### 1.4.1 충분하지 않은 훈련 데이터 

- 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다.

#### 1.4.2 대표성 없는 훈련데이터 

- 일반화가 잘 되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다. 
- 샘플이 작으면 샘플링 잡음(Sampling Noise), 데이터가 많다고 하더라도 잘못된 대표성을 띠지 못할 수 있음. 이를 샘플링 편향(Sampling Bias)라고 한다. 

#### 1.4.3 낮은 품질의 데이터 

#### 1.4.4 관련 없는 특성 

- Garbage in, Garbage out
- 핵시 ㅁ요소는 훈련에 사용할 좋은 특성을 찾는 것. 이를**Feature Engineering**이라고 한다.
- **Feature selection** : 특성 선택
- **Feature Extraction** : 특성을 결합하여 더 유용한 특성을 만든다. /​

#### 1.4.5 Overfitting

- 과도한 일반화 => 일반성이 떨어짐.
- 해결 방법 
  - 파라미터 수가 적은 모델을 선택하거나 특성 수를 줄이거나, 모델에 제약을 가하여 단순화
  - 훈련 데이터를 더 많이 모은다.
  - 잡음을 줄인다( 예- 데이터 수정과 이상치 제거)
- 모델에 제약을 가하는 것을 **Regularization(규제)** 라고 함. 

#### 1.4.6 Underfitting 

- 모델이 너무 단순해서 내재된 구조를 학습하지 못할 떄 일어남
- 해결 방법
  - 파라미터가 더 많은 모델을 선택
  - 학습 알고리즘에 더 좋은 특성을 제공(Feature Engineering)
  - 모델의 제약을 줄인다. 



#### 1.4.7 정리 

- 머신러닝은 명시적 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 자랗도록 만드는 것이다.
- 머신러닝 종류에는 지도와 비지도 학습, 배치와 온라인 학습, 사례 기반과 모델/ 기반 학습 등이 있다.
- 훈련 세트가 너무 적거나, 대표성이 없는 데이터거나, 잡음이 많고 관련 없는 특성으로 여염되어 있다면 시스템이 잘 작동 하지 않는다.



### 1.5 테스트와 검증

- 훈련 데이터를 **훈련 세트** 와 **테스트 세트** 두개로 나누는 것. 
- 자세한 내용은 책을 참조하거나 Cross Vaildation 과 같은 부분을 찾아 보면 된다. 



